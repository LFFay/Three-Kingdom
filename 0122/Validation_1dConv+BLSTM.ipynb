{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c21c69e1fa984d63c4fbeba997b1f676cec063be",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_name(file_dir): \n",
    "    dic={}\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        dic[root]=files\n",
    "#         print(root) #path\n",
    "#         print(dirs) #subdirectory\n",
    "#         print(files) #files in non-subdirectory\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "455b93f4c94d3a658a84e56119f256df8ed2a1c9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AutomaticExtractionData=file_name(\"./OU-IneritialGaitData/AutomaticExtractionData_IMUZCenter\")\n",
    "ManualExtractionData=file_name(\"./OU-IneritialGaitData/ManualExtractionData\")\n",
    "ManualExtractionData_name= list(ManualExtractionData.keys())[1:]\n",
    "SimilarAction = file_name(\"./OU-IneritialGaitActionDataset\")\n",
    "SimilarAction_name = list(SimilarAction.keys())[1:4]\n",
    "label=pd.read_csv('./IDGenderAgelist_ig.csv',dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a569c9ad3a62d79a05f789f25d7f3ea4fa3f9b97",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_ID_number(x):\n",
    "    if len(x)==3:\n",
    "        return ('000' + x)\n",
    "    elif len(x)==4:\n",
    "        return ('00' + x)\n",
    "    elif len(x)==5:\n",
    "        return ('0' + x)\n",
    "    else:\n",
    "        return x\n",
    "      \n",
    "label['adjusted_ID']=label['ID'].apply(lambda x: change_ID_number(x))\n",
    "def file_name_with_ID(x,post,ls):\n",
    "    for i in range(len(list(ls))):\n",
    "        if (x == ls[i][5:11] and ls[i][12:]== post):\n",
    "            return(ls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "865fe3b88afd9ba202a99c5e77f1f059d1fe8041",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label['AutomaticExtractionData_IMUZCenter_Walk_1']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Center_seq0.csv',list(AutomaticExtractionData.values())[0]))\n",
    "label['AutomaticExtractionData_IMUZCenter_Walk_2']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Center_seq1.csv',list(AutomaticExtractionData.values())[0]))\n",
    "label['ManualExtractionData/IMUZCenter_Walk_1']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk1.csv',ManualExtractionData[ManualExtractionData_name[0]]))\n",
    "label['ManualExtractionData/IMUZCenter_Walk_2']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk2.csv',ManualExtractionData[ManualExtractionData_name[0]]))\n",
    "label['ManualExtractionData/IMUZCenter_SlopeDown']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeDown.csv',ManualExtractionData[ManualExtractionData_name[0]]))\n",
    "label['ManualExtractionData/IMUZCenter_SlopeUp']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeUp.csv',ManualExtractionData[ManualExtractionData_name[0]]))\n",
    "label['ManualExtractionData/IMUZRight_Walk_1']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk1.csv',ManualExtractionData[ManualExtractionData_name[1]]))\n",
    "label['ManualExtractionData/IMUZRight_Walk_2']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk2.csv',ManualExtractionData[ManualExtractionData_name[1]]))\n",
    "label['ManualExtractionData/IMUZRight_SlopeDown']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeDown.csv',ManualExtractionData[ManualExtractionData_name[1]]))\n",
    "label['ManualExtractionData/IMUZRight_SlopeUp']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeUp.csv',ManualExtractionData[ManualExtractionData_name[1]]))\n",
    "label['ManualExtractionData/IMUZLeft_Walk_1']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk1.csv',ManualExtractionData[ManualExtractionData_name[2]]))\n",
    "label['ManualExtractionData/IMUZLeft_Walk_2']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk2.csv',ManualExtractionData[ManualExtractionData_name[2]]))\n",
    "label['ManualExtractionData/IMUZLeft_SlopeDown']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeDown.csv',ManualExtractionData[ManualExtractionData_name[2]]))\n",
    "label['ManualExtractionData/IMUZLeft_SlopeUp']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeUp.csv',ManualExtractionData[ManualExtractionData_name[2]]))\n",
    "label['ManualExtractionData/Android_Walk_1']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk1.csv',ManualExtractionData[ManualExtractionData_name[3]]))\n",
    "label['ManualExtractionData/Android_Walk_2']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk2.csv',ManualExtractionData[ManualExtractionData_name[3]]))\n",
    "label['ManualExtractionData/Android_SlopeDown']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeDown.csv',ManualExtractionData[ManualExtractionData_name[3]]))\n",
    "label['ManualExtractionDataAndroid_SlopeUp']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeUp.csv',ManualExtractionData[ManualExtractionData_name[3]]))\n",
    "label['SimilarActionLeftSensor']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'actLabel',SimilarAction[SimilarAction_name[0]]))\n",
    "label['SimilarActionRightSensor']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'actLabel',SimilarAction[SimilarAction_name[0]]))\n",
    "label['SimilarActionCenterSensor']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'actLabel',SimilarAction[SimilarAction_name[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8db3cdfb9f91ab7e8ec225116d1c1c3244353d2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_name = \"\"\n",
    "path_name_act = \"./OU-IneritialGaitActionDataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b867237442574b1cad9f54937864e9b0f4a2cac",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_read_table(path,fileName,actionName,ID,label): \n",
    "  #try:\n",
    "    dataset_name= fileName + actionName\n",
    "    path_name= fileName +'/'+ str(label[label['ID']==ID][dataset_name].values[0])\n",
    "    if fileName=='ManualExtractionData/Android':\n",
    "      df=pd.read_csv(path_name,skiprows=2)\n",
    "      df.columns=[0,0,0,df.columns.values[3],df.columns.values[4],df.columns.values[5]]\n",
    "      insert_line=pd.DataFrame(df.columns.values).T\n",
    "      df.columns=insert_line.columns\n",
    "      df=pd.concat([insert_line,df],axis=0)\n",
    "    elif fileName == \"SimilarAction\":\n",
    "      df=pd.read_table(path + actionName + \"/\" + str(label[label['ID']==ID][dataset_name].values[0]) ,skiprows=1)\n",
    "      return df\n",
    "      df.columns=[0,0,0,df.columns.values[3],df.columns.values[4],df.columns.values[5]]\n",
    "      insert_line=pd.DataFrame(df.columns.values).T\n",
    "      df.columns=insert_line.columns\n",
    "      df=pd.concat([insert_line,df],axis=0)\n",
    "    else:\n",
    "      df=pd.read_csv(path_name,skiprows=2)\n",
    "      insert_line=pd.DataFrame(df.columns.values).T\n",
    "      df.columns=insert_line.columns\n",
    "      df=pd.concat([insert_line,df],axis=0)\n",
    "    df.columns=['Gx','Gy','Gz','Ax','Ay','Az']\n",
    "    df = df.astype(float)\n",
    "    return df\n",
    "  #except:\n",
    "    #return None\n",
    "df = generate_read_table(path_name, 'AutomaticExtractionData_IMUZCenter','_Walk_1','002318',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f63a2033fd468f17ce4c17afd84586a2546963c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b012c85c3bf7ba867e050dcc39ebad2b14f3d13",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = generate_read_table(path_name_act, 'SimilarAction','LeftSensor','000104',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4c872d2f6a727e9f816d2fc347e8dfefd06b96e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[:5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2917aa20bc7910db12974c90172bfcbb825557d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[\"Label\"].plot()\n",
    "#df[df[\"Label\"] == 4].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb9c736886208dbc277e9b5ac2bf463469b2b9a8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def yipeng_preprocessing(raw_data, length):\n",
    "            \n",
    "  # Data augmentation\n",
    "  if raw_data.shape[0] > length:\n",
    "    #data = raw_data[0:length] # Cut the data\n",
    "    start_index = random.randrange(len(raw_data) - (length))\n",
    "    data = raw_data[start_index: start_index + length]\n",
    "  else:\n",
    "    period = math.ceil(length / raw_data.shape[0])\n",
    "    temp = np.copy(raw_data)\n",
    "    # copy the data periodic\n",
    "    for i in range(period-1):\n",
    "      temp = np.row_stack((temp, raw_data))\n",
    "      data = (temp[0:length]) # Cut the data\n",
    "            \n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "99c35b840b2d936be4ddac65a1a9385058226add",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "df = pd.read_csv('../input/IDGenderAgelist_ig.csv')\n",
    "ids = df[\"ID\"].values\n",
    "gender = df[\"Gender(0:Female;1:Male)\"].values\n",
    "age = copy.deepcopy(df[\"Age\"].values)\n",
    "act_age = df[\"Age\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e0e9b30cc44ece542c62d310e54d5a28cc35fef3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "#for i in range(0,40):\n",
    "#    age[(age > (i * 2.5)) & (age <= ((i + 1) * 2.5))] = i\n",
    "#for i in range(0,20):\n",
    "#    age[(age > (i * 5.0)) & (age <= ((i + 1) * 5.0))] = i\n",
    "for i in range(0,10):\n",
    "    age[(age > (i * 10.0)) & (age <= ((i + 1) * 10.0))] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2cc34d538dfa12ef9b5c9094aa5a9c0a00eb4df8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(age,bins = 32)\n",
    "#plt.hist(age,bins = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31fdc4b603149a2a9570a93ba1394935d4c31bf6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_categorical(age).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08230eed5af6009e6c1cd8cff48fd3ab2e6b47a9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cccc0b849c0c1223bdbdc8dff357888f40595b36",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, LSTM, Bidirectional, Dropout, Flatten, Dense, TimeDistributed, GlobalMaxPooling1D, Conv2D, Reshape, Activation, Add, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv1D, UpSampling1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.losses import categorical_crossentropy, binary_crossentropy, mae\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#Deep Convoluional LSTM model\n",
    "\"\"\"\n",
    "\n",
    "def get_model(n_timesteps,n_features):\n",
    "  inputs = Input(shape=(n_timesteps,n_features,))\n",
    "  x = Conv1D(256, 8, padding='same', activation='relu')(inputs)\n",
    "  x = Conv1D(256, 8, padding='same', activation='relu')(x)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(128, 8, padding='same', activation='relu')(x)\n",
    "  x = resblock(x,128,8)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(64, 8, padding='same', activation='relu')(x)\n",
    "  x = resblock(x,64,8)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(16, 8, padding='same', activation='relu')(x)\n",
    "  x = resblock(x,16,8)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(8, 4, padding='same', activation='relu')(x)\n",
    "  x = resblock(x,8,4)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Bidirectional(LSTM(10,return_sequences=True))(x)\n",
    "  x = Bidirectional(LSTM(10))(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  predictions = Dense(1, activation='sigmoid')(x)\n",
    "  \n",
    "  model = Model(inputs=inputs, outputs = predictions)\n",
    "  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "  return model \n",
    "\n",
    "def resblock(x, filters, kernel_size):\n",
    "    x_ = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x_ = BatchNormalization()(x_)\n",
    "    x_ = Activation(LeakyReLU())(x_)\n",
    "    x_ = Conv1D(filters, kernel_size, padding='same')(x_)\n",
    "    x = Add()([x_, x])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(LeakyReLU())(x)\n",
    "    return x\n",
    "\n",
    "\"\"\"\n",
    "def get_model(n_timesteps,n_features):\n",
    "  inputs = Input(shape=(n_timesteps,n_features,))\n",
    "  x = Conv1D(256, 11, padding='same', activation='relu')(inputs)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(256, 11, padding='same', activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(128, 11, padding='same', activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Conv1D(64, 11, padding='same', activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Bidirectional(LSTM(100,return_sequences=True))(x)\n",
    "  x = Bidirectional(LSTM(100))(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  \n",
    "  x_gender = Dense(100, activation='relu')(x)\n",
    "  gender = Dense(1, activation='sigmoid',name='gender')(x_gender)\n",
    "  \n",
    "  x_age = Dense(100, activation='relu')(x)\n",
    "  age = Dense(8, activation='softmax',name='age')(x_age)\n",
    "  \n",
    "  #x_data = Dense(100, activation='relu')(x)\n",
    "  #data = Dense(3, activation='softmax',name='dataset')(x_data)\n",
    "  \n",
    "    \n",
    "  outputs = [gender, age]\n",
    "  \n",
    "  model = Model(inputs=inputs, outputs = outputs)\n",
    "  sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "  model.compile(loss={'gender': binary_crossentropy, 'age': categorical_crossentropy},\n",
    "                  loss_weights={'gender': 0.50, 'age': 0.50},\n",
    "                optimizer= \"adam\", metrics=['accuracy'])\n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e049bd444d6a72adfb1c239b05a80ef5cceb7e60",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max(y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        temp = y_pred[i]\n",
    "        temp[np.argmax(temp)] = 1\n",
    "        temp[temp != 1] = 0\n",
    "        y_pred[i] = temp\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e63f15167f11bfbdf4076cec53c14e42a59a43a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oversample(x_train, gender_train, age_train, dataset_train, limit):\n",
    "    age_train_index = np.argmax(age_train,axis = 1)\n",
    "    ls_class_size = []\n",
    "    for i in range(0,8):\n",
    "        ls_class_size.append(np.sum(age_train_index == i))\n",
    "\n",
    "    max_class_size = max(ls_class_size)\n",
    "    max_index = np.argmax(ls_class_size)\n",
    "    aug_x = []\n",
    "    aug_age = []\n",
    "    aug_gender = []\n",
    "    aug_dataset = []\n",
    "\n",
    "    for i in tqdm(range(0,8)):\n",
    "        if(i == max_index):\n",
    "            continue\n",
    "        c = 0\n",
    "        if(ls_class_size[i] == 0):\n",
    "            continue\n",
    "        temp = []\n",
    "        temp_age = []\n",
    "        temp_gender = []\n",
    "        temp_dataset= []\n",
    "        while((ls_class_size[i] + c) <= max_class_size):\n",
    "            index = random.randrange(ls_class_size[i])\n",
    "            temp.append(x_train[age_train_index == i][index])\n",
    "            temp_age.append(age_train[age_train_index == i][index])\n",
    "            temp_gender.append(gender_train[age_train_index == i][index])\n",
    "            temp_dataset.append(dataset_train[age_train_index == i][index])\n",
    "            c += 1\n",
    "            if(c == limit):\n",
    "                break\n",
    "        aug_x.extend(np.array(temp))\n",
    "        aug_age.extend(np.array(temp_age))\n",
    "        aug_gender.extend(np.array(temp_gender))\n",
    "        aug_dataset.extend(np.array(temp_dataset))\n",
    "        del temp\n",
    "        del temp_age\n",
    "        del temp_gender\n",
    "        del temp_dataset\n",
    "        gc.collect()\n",
    "    aug_x = np.array(aug_x)\n",
    "    aug_age = np.array(aug_age)\n",
    "    aug_gender = np.array(aug_gender)\n",
    "    aug_dataset = np.array(aug_dataset)\n",
    "    \n",
    "    return aug_x, aug_age, aug_gender, aug_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3caa212bb9a66a6e95587697504f5d59a9398b28",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "\n",
    "ls_acc = []\n",
    "ls_mae = []\n",
    "ls_mae_2 = []\n",
    "ls_mae_3 = []\n",
    "\n",
    "length = 500\n",
    "\n",
    "datasets = label.columns[4:]\n",
    "file_name=['AutomaticExtractionData_IMUZCenter','ManualExtractionData/IMUZCenter','ManualExtractionData/IMUZRight',\n",
    "          'ManualExtractionData/IMUZLeft','ManualExtractionData/Android']\n",
    "action_name=['_Walk_1','_Walk_2','_SlopeDown','_SlopeUp']\n",
    "sensor_loc = [\"CenterSensor\", \"RightSensor\", \"LeftSensor\"]\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "for train_index, test_index in skf.split(ids, gender):\n",
    "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "    ids_train, ids_test = ids[train_index], ids[test_index]\n",
    "    gender_train, gender_test = gender[train_index], gender[test_index]\n",
    "    age_dummy = to_categorical(age)\n",
    "    age_train, age_test = age_dummy[train_index], age_dummy[test_index]\n",
    "    #age_train, age_test = act_age[train_index], act_age[test_index]\n",
    "    _, act_age_test = act_age[train_index], act_age[test_index]\n",
    "    ids_train, ids_valid, gender_train, gender_valid, age_train, age_valid  = train_test_split(ids_train, gender_train, age_train,  test_size=0.10, random_state=42)\n",
    "    \n",
    "    x_train = []\n",
    "    new_y_train = []\n",
    "    new_gender_train = []\n",
    "    new_age_train = []\n",
    "    sensor_train = []\n",
    "    for i in tqdm(range(0,len(ids_train))):\n",
    "        subject_id = change_ID_number(str(ids_train[i]))\n",
    "        for k in range(0,len(file_name) - 1):\n",
    "            for l in range(0,len(action_name)):\n",
    "                try:\n",
    "                    #for c in range(0,3):\n",
    "                        df_subject = generate_read_table(path_name,file_name[k], action_name[l],subject_id,label)\n",
    "                        sc = StandardScaler()\n",
    "                        df_subject = pd.DataFrame(sc.fit_transform(df_subject))\n",
    "                        temp_x = yipeng_preprocessing(df_subject.values, length)\n",
    "                        x_train.append(temp_x)\n",
    "                        new_gender_train.append(gender_train[i])\n",
    "                        new_age_train.append(age_train[i])\n",
    "                        if(k == 0 or k == 1):\n",
    "                            sensor_train.append(0)\n",
    "                        elif(k == 2):\n",
    "                            sensor_train.append(1)\n",
    "                        elif(k == 3):\n",
    "                            sensor_train.append(2)\n",
    "                except: \n",
    "                    continue\n",
    "                \n",
    "        for k in range(0,3):\n",
    "            try:\n",
    "                df_subject = generate_read_table(path_name_act,'SimilarAction',sensor_loc[k],subject_id,label)\n",
    "                del df_subject[\"Label\"]\n",
    "                sc = StandardScaler()\n",
    "                df_subject = pd.DataFrame(sc.fit_transform(df_subject))\n",
    "                #temp_x = yipeng_preprocessing(df_subject.values, length)\n",
    "                start_index = 0\n",
    "                while(start_index + length < len(df_subject)):\n",
    "                    temp_x = df_subject.values[start_index:start_index + length]\n",
    "                    x_train.append(temp_x)\n",
    "                    new_gender_train.append(gender_train[i])\n",
    "                    new_age_train.append(age_train[i])\n",
    "                    sensor_train.append(k)\n",
    "                    start_index += length\n",
    "            except: \n",
    "                continue\n",
    "            \n",
    "    x_valid = []\n",
    "    new_gender_valid = []\n",
    "    new_age_valid = []\n",
    "    sensor_valid = []\n",
    "    \n",
    "    for i in tqdm(range(0,len(ids_valid))):\n",
    "        subject_id = change_ID_number(str(ids_valid[i]))\n",
    "        for k in range(0,3):\n",
    "            try:\n",
    "                df_subject = generate_read_table(path_name_act,'SimilarAction',sensor_loc[k],subject_id,label)\n",
    "                del df_subject[\"Label\"]\n",
    "                sc = StandardScaler()\n",
    "                df_subject = pd.DataFrame(sc.fit_transform(df_subject))\n",
    "                start_index = 0\n",
    "                while(start_index + length < len(df_subject)):\n",
    "                    temp_x = df_subject.values[start_index:start_index + length]\n",
    "                    x_valid.append(temp_x)\n",
    "                    new_gender_valid.append(gender_valid[i])\n",
    "                    new_age_valid.append(age_valid[i])\n",
    "                    sensor_valid.append(k)\n",
    "                    start_index += length \n",
    "            except:\n",
    "                continue\n",
    "           \n",
    "    x_test = []\n",
    "    new_gender_test = []\n",
    "    new_age_test= []\n",
    "    new_act_age_test = []\n",
    "    ls_count = []\n",
    "     \n",
    "    for i in tqdm(range(0,len(ids_test))):\n",
    "        subject_id = change_ID_number(str(ids_test[i]))\n",
    "        for k in range(0,3):\n",
    "            try:\n",
    "                df_subject = generate_read_table(path_name_act,'SimilarAction',sensor_loc[k],subject_id,label)\n",
    "                del df_subject[\"Label\"]\n",
    "                sc = StandardScaler()\n",
    "                df_subject = pd.DataFrame(sc.fit_transform(df_subject))\n",
    "                start_index = 0\n",
    "                c = 0\n",
    "                while(start_index + length < len(df_subject)):\n",
    "                    temp_x = df_subject.values[start_index:start_index + length]\n",
    "                    x_test.append(temp_x)                    \n",
    "                    start_index += length\n",
    "                    c += 1\n",
    "                ls_count.append(c)\n",
    "                new_gender_test.append(gender_test[i])\n",
    "                new_age_test.append(age_test[i])\n",
    "                new_act_age_test.append(act_age_test[i])\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    print(\"Train size: \" + str(len(x_train)))\n",
    "    print(\"Valid size: \" + str(len(x_valid)))\n",
    "    print(\"Test size: \" + str(len(x_test)))\n",
    "    x_train = np.array(x_train)\n",
    "    x_valid = np.array(x_valid)\n",
    "    x_test = np.array(x_test)\n",
    "    gender_train = np.array(new_gender_train)\n",
    "    gender_valid = np.array(new_gender_valid)\n",
    "    gender_test = np.array(new_gender_test)\n",
    "    age_train = np.array(new_age_train)\n",
    "    age_valid = np.array(new_age_valid)\n",
    "    age_test = np.array(new_age_test)\n",
    "    act_age_test = np.array(new_act_age_test)\n",
    "        \n",
    "    sensor_train = to_categorical(sensor_train)\n",
    "    #sensor_valid = to_categorical(sensor_valid)\n",
    "        \n",
    "    #del new_gender_train, new_gender_valid, new_gender_test, new_age_train, new_age_valid, new_age_test, new_act_age_test\n",
    "    #gc.collect()\n",
    "    \n",
    "    #aug_x, aug_age, aug_gender, aug_sensor = oversample(x_train, gender_train, age_train, sensor_train, 1000)\n",
    "    #x_train = np.concatenate([x_train,aug_x])\n",
    "    #age_train = np.concatenate([age_train,aug_age])\n",
    "    #gender_train = np.concatenate([gender_train,aug_gender])\n",
    "    #sensor_train = np.concatenate([sensor_train,aug_sensor])\n",
    "    \n",
    "    model = get_model(x_train.shape[1],x_train.shape[2])\n",
    "    #result = model.fit(x_train, [gender_train, age_train, sensor_train], validation_data = (x_valid,[gender_valid, age_valid, sensor_valid]),epochs= 15, batch_size = 256)\n",
    "    result = model.fit(x_train, [gender_train, age_train], validation_data = (x_valid,[gender_valid, age_valid]),epochs= 10, batch_size = 256)   \n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    #del x_train, gender_train, age_train, sensor_train, x_valid, gender_valid, age_valid, sensor_valid\n",
    "    gc.collect()\n",
    "    \n",
    "    gender_pred = []\n",
    "    age_pred = []\n",
    "    c = 0\n",
    "    for i in range(len(ls_count)):\n",
    "        gender_pred.append(y_pred[0][c:c + ls_count[i]].mean())\n",
    "        age_pred.append(np.mean(y_pred[1][c:c + ls_count[i]], axis = 0))\n",
    "        c += ls_count[i]\n",
    "    gender_pred = np.array(gender_pred)\n",
    "    age_pred = np.array(age_pred)\n",
    "    \n",
    "    gender_pred[gender_pred < 0.5] = 0\n",
    "    gender_pred[gender_pred >= 0.5] = 1\n",
    "    print(accuracy_score(gender_pred,gender_test))\n",
    "    ls_acc.append(accuracy_score(gender_pred,gender_test))\n",
    "    \n",
    "    \n",
    "    #Mean to Class Method\n",
    "    age_pred = get_max(age_pred)\n",
    "    print(accuracy_score(np.array(age_pred),age_test))\n",
    "    _, age_pred_index = np.where(age_pred == 1.0)\n",
    "    mean_age = age_pred_index #* 2.5 + 1.25\n",
    "    #mean_age = age_pred_index * 5.0 + 2.5\n",
    "    mean_age = age_pred_index * 10.0 + 5.0\n",
    "    print(np.mean(abs(act_age_test - mean_age)))\n",
    "    ls_mae.append(np.mean(abs(act_age_test - mean_age)))\n",
    "    \n",
    "    #Mean Class age calculation\n",
    "    age_pred = []\n",
    "    c = 0\n",
    "    for i in range(len(ls_count)):\n",
    "        temp = get_max(np.array(y_pred[1][c:c + ls_count[i]]))\n",
    "        _, age_pred_index = np.where(temp == 1.0)\n",
    "        mean_age = age_pred_index #* 2.5 + 1.25\n",
    "        #mean_age = age_pred_index * 5.0 + 2.5\n",
    "        mean_age = age_pred_index * 10.0 + 5.0\n",
    "        age_pred.append(np.mean(mean_age))\n",
    "        c += ls_count[i]\n",
    "    age_pred = np.array(age_pred)\n",
    "    print(np.mean(abs(act_age_test - age_pred)))\n",
    "    ls_mae_2.append(np.mean(abs(act_age_test - age_pred)))\n",
    "    \n",
    "    age_pred = []\n",
    "    c = 0\n",
    "    for i in range(len(ls_count)):\n",
    "        mean_age = np.mean(np.sum(np.array(y_pred[1][c:c + ls_count[i]])\n",
    "                                  * (np.array(list(range(0,8))) * 10.0 + 5.0), axis = 1))\n",
    "        age_pred.append(mean_age)\n",
    "        c += ls_count[i]\n",
    "    age_pred = np.array(age_pred)\n",
    "    print(np.mean(abs(act_age_test - age_pred)))\n",
    "    ls_mae_3.append(np.mean(abs(act_age_test - age_pred)))\n",
    "    K.clear_session()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d44bae6d8a9a6da73d46946dc13fc08f6c98a559",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.array(list(range(1,80))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f2aeb95895bb42ee7f8212a6851089e93adff57",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee35cf7fa88ea5b8da4ec4d3799829a5e17c86c1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(np.array(list(range(0,16))) * 5 + 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7f1ada278e1957b56175894b5404f8cf58e98c3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot(ls_acc)\n",
    "plt.savefig(\"result_gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86c1dcf08f00dbf357a9a13fa3f8a2299f24c9ed",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot(ls_mae)\n",
    "plt.savefig(\"result_age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f0c64c4084ba199e37cbb008551c98605278bc0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot(ls_mae_2)\n",
    "plt.savefig(\"result_age_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "421a6a281087d6ad9e8e179d89def2fcea476d78",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot(ls_mae_3)\n",
    "plt.savefig(\"result_age_3\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
