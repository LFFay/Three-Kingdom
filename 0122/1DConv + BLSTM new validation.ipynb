{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "793f10aa3dd073cb32b15fd862f69a4dca2d14ce",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Protocols', 'AutomaticExtractionData_IMUZCenter', 'ManualExtractionData']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input/ou-ineritialgaitdata/OU-IneritialGaitData\"))\n",
    "path_name = '../input/ou-ineritialgaitdata/OU-IneritialGaitData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c21c69e1fa984d63c4fbeba997b1f676cec063be",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_name(file_dir): \n",
    "    dic={}\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        dic[root]=files\n",
    "#         print(root) #path\n",
    "#         print(dirs) #subdirectory\n",
    "#         print(files) #files in non-subdirectory\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "455b93f4c94d3a658a84e56119f256df8ed2a1c9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AutomaticExtractionData=file_name(\"../input/ou-ineritialgaitdata/OU-IneritialGaitData/AutomaticExtractionData_IMUZCenter\")\n",
    "ManualExtractionData=file_name(\"../input/ou-ineritialgaitdata/OU-IneritialGaitData/ManualExtractionData\")\n",
    "ManualExtractionData_name= list(ManualExtractionData.keys())[1:]\n",
    "SimilarAction = file_name(\"../input/ou-ineritialgaitactiondataset/OU-IneritialGaitActionDataset\")\n",
    "SimilarAction_name = list(SimilarAction.keys())[1:4]\n",
    "label=pd.read_csv('../input/IDGenderAgelist_ig.csv',dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "a569c9ad3a62d79a05f789f25d7f3ea4fa3f9b97",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_ID_number(x):\n",
    "    if len(x)==3:\n",
    "        return ('000' + x)\n",
    "    elif len(x)==4:\n",
    "        return ('00' + x)\n",
    "    elif len(x)==5:\n",
    "        return ('0' + x)\n",
    "    else:\n",
    "        return x\n",
    "      \n",
    "label['adjusted_ID']=label['ID'].apply(lambda x: change_ID_number(x))\n",
    "def file_name_with_ID(x,post,ls):\n",
    "    for i in range(len(list(ls))):\n",
    "        if (x == ls[i][5:11] and ls[i][12:]== post):\n",
    "            return(ls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "865fe3b88afd9ba202a99c5e77f1f059d1fe8041",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label['AutomaticExtractionData_IMUZCenter_Walk_1']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Center_seq0.csv',list(AutomaticExtractionData.values())[0]))\n",
    "label['AutomaticExtractionData_IMUZCenter_Walk_2']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Center_seq1.csv',list(AutomaticExtractionData.values())[0]))\n",
    "label['ManualExtractionData/IMUZCenter_Walk_1']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk1.csv',ManualExtractionData[ManualExtractionData_name[0]]))\n",
    "label['ManualExtractionData/IMUZCenter_Walk_2']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk2.csv',ManualExtractionData[ManualExtractionData_name[0]]))\n",
    "label['ManualExtractionData/IMUZCenter_SlopeDown']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeDown.csv',ManualExtractionData[ManualExtractionData_name[0]]))\n",
    "label['ManualExtractionData/IMUZCenter_SlopeUp']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeUp.csv',ManualExtractionData[ManualExtractionData_name[0]]))\n",
    "label['ManualExtractionData/IMUZRight_Walk_1']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk1.csv',ManualExtractionData[ManualExtractionData_name[1]]))\n",
    "label['ManualExtractionData/IMUZRight_Walk_2']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk2.csv',ManualExtractionData[ManualExtractionData_name[1]]))\n",
    "label['ManualExtractionData/IMUZRight_SlopeDown']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeDown.csv',ManualExtractionData[ManualExtractionData_name[1]]))\n",
    "label['ManualExtractionData/IMUZRight_SlopeUp']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeUp.csv',ManualExtractionData[ManualExtractionData_name[1]]))\n",
    "label['ManualExtractionData/IMUZLeft_Walk_1']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk1.csv',ManualExtractionData[ManualExtractionData_name[2]]))\n",
    "label['ManualExtractionData/IMUZLeft_Walk_2']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk2.csv',ManualExtractionData[ManualExtractionData_name[2]]))\n",
    "label['ManualExtractionData/IMUZLeft_SlopeDown']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeDown.csv',ManualExtractionData[ManualExtractionData_name[2]]))\n",
    "label['ManualExtractionData/IMUZLeft_SlopeUp']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeUp.csv',ManualExtractionData[ManualExtractionData_name[2]]))\n",
    "label['ManualExtractionData/Android_Walk_1']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk1.csv',ManualExtractionData[ManualExtractionData_name[3]]))\n",
    "label['ManualExtractionData/Android_Walk_2']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'Walk2.csv',ManualExtractionData[ManualExtractionData_name[3]]))\n",
    "label['ManualExtractionData/Android_SlopeDown']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeDown.csv',ManualExtractionData[ManualExtractionData_name[3]]))\n",
    "label['ManualExtractionDataAndroid_SlopeUp']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'SlopeUp.csv',ManualExtractionData[ManualExtractionData_name[3]]))\n",
    "label['SimilarActionLeftSensor']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'actLabel',SimilarAction[SimilarAction_name[0]]))\n",
    "label['SimilarActionRightSensor']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'actLabel',SimilarAction[SimilarAction_name[0]]))\n",
    "label['SimilarActionCenterSensor']=label['adjusted_ID'].apply(lambda x: \n",
    "                                file_name_with_ID(x,'actLabel',SimilarAction[SimilarAction_name[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d8db3cdfb9f91ab7e8ec225116d1c1c3244353d2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_name_act = \"../input/ou-ineritialgaitactiondataset/OU-IneritialGaitActionDataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "4b867237442574b1cad9f54937864e9b0f4a2cac",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_read_table(path,fileName,actionName,ID,label): \n",
    "  #try:\n",
    "    dataset_name= fileName + actionName\n",
    "    path_name= fileName +'/'+ str(label[label['ID']==ID][dataset_name].values[0])\n",
    "    if fileName=='ManualExtractionData/Android':\n",
    "      df=pd.read_csv(path + path_name,skiprows=2)\n",
    "      df.columns=[0,0,0,df.columns.values[3],df.columns.values[4],df.columns.values[5]]\n",
    "      insert_line=pd.DataFrame(df.columns.values).T\n",
    "      df.columns=insert_line.columns\n",
    "      df=pd.concat([insert_line,df],axis=0)\n",
    "    elif fileName == \"SimilarAction\":\n",
    "      df=pd.read_table(path + actionName + \"/\" + str(label[label['ID']==ID][dataset_name].values[0]) ,skiprows=1)\n",
    "      return df\n",
    "      df.columns=[0,0,0,df.columns.values[3],df.columns.values[4],df.columns.values[5]]\n",
    "      insert_line=pd.DataFrame(df.columns.values).T\n",
    "      df.columns=insert_line.columns\n",
    "      df=pd.concat([insert_line,df],axis=0)\n",
    "    else:\n",
    "      df=pd.read_csv(path + path_name,skiprows=2)\n",
    "      insert_line=pd.DataFrame(df.columns.values).T\n",
    "      df.columns=insert_line.columns\n",
    "      df=pd.concat([insert_line,df],axis=0)\n",
    "    df.columns=['Gx','Gy','Gz','Ax','Ay','Az']\n",
    "    df = df.astype(float)\n",
    "    return df\n",
    "  #except:\n",
    "    #return None\n",
    "df = generate_read_table(path_name, 'AutomaticExtractionData_IMUZCenter','_Walk_1','002318',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "5f63a2033fd468f17ce4c17afd84586a2546963c",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gx</th>\n",
       "      <th>Gy</th>\n",
       "      <th>Gz</th>\n",
       "      <th>Ax</th>\n",
       "      <th>Ay</th>\n",
       "      <th>Az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.236353</td>\n",
       "      <td>-0.627744</td>\n",
       "      <td>0.041949</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.826</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.177763</td>\n",
       "      <td>-0.622424</td>\n",
       "      <td>-0.053925</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044605</td>\n",
       "      <td>-0.638404</td>\n",
       "      <td>-0.181756</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.045942</td>\n",
       "      <td>-0.670364</td>\n",
       "      <td>-0.309588</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.822</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.056595</td>\n",
       "      <td>-0.643724</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.844</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gx        Gy        Gz     Ax     Ay     Az\n",
       "0  0.236353 -0.627744  0.041949 -0.024 -0.826  0.150\n",
       "0  0.177763 -0.622424 -0.053925  0.006 -0.834  0.148\n",
       "1  0.044605 -0.638404 -0.181756  0.028 -0.824  0.148\n",
       "2 -0.045942 -0.670364 -0.309588  0.040 -0.822  0.084\n",
       "3 -0.056595 -0.643724 -0.384157  0.060 -0.844  0.026"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "1b012c85c3bf7ba867e050dcc39ebad2b14f3d13",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = generate_read_table(path_name_act, 'SimilarAction','LeftSensor','000104',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "e4c872d2f6a727e9f816d2fc347e8dfefd06b96e",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gx</th>\n",
       "      <th>Gy</th>\n",
       "      <th>Gz</th>\n",
       "      <th>Ax</th>\n",
       "      <th>Ay</th>\n",
       "      <th>Az</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.024172</td>\n",
       "      <td>-0.454651</td>\n",
       "      <td>0.173332</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.770</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.018845</td>\n",
       "      <td>-0.433345</td>\n",
       "      <td>0.168006</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018439</td>\n",
       "      <td>-0.428019</td>\n",
       "      <td>0.157353</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.758</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002460</td>\n",
       "      <td>-0.348124</td>\n",
       "      <td>0.104090</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.760</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055723</td>\n",
       "      <td>-0.273556</td>\n",
       "      <td>0.072132</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.780</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gx        Gy        Gz     Ax     Ay     Az  Label\n",
       "0 -0.024172 -0.454651  0.173332  0.052 -0.770 -0.138      0\n",
       "1 -0.018845 -0.433345  0.168006  0.072 -0.766 -0.142      0\n",
       "2  0.018439 -0.428019  0.157353  0.110 -0.758 -0.138      0\n",
       "3  0.002460 -0.348124  0.104090  0.130 -0.760 -0.134      0\n",
       "4  0.055723 -0.273556  0.072132  0.150 -0.780 -0.122      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "d2917aa20bc7910db12974c90172bfcbb825557d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[\"Label\"].plot()\n",
    "#df[df[\"Label\"] == 4].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "cb9c736886208dbc277e9b5ac2bf463469b2b9a8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def yipeng_preprocessing(raw_data, length):\n",
    "            \n",
    "  # Data augmentation\n",
    "  if raw_data.shape[0] > length:\n",
    "    #data = raw_data[0:length] # Cut the data\n",
    "    start_index = random.randrange(len(raw_data) - (length))\n",
    "    data = raw_data[start_index: start_index + length]\n",
    "  else:\n",
    "    period = math.ceil(length / raw_data.shape[0])\n",
    "    temp = np.copy(raw_data)\n",
    "    # copy the data periodic\n",
    "    for i in range(period-1):\n",
    "      temp = np.row_stack((temp, raw_data))\n",
    "      data = (temp[0:length]) # Cut the data\n",
    "            \n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "99c35b840b2d936be4ddac65a1a9385058226add",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "df = pd.read_csv('../input/IDGenderAgelist_ig.csv')\n",
    "ids = df[\"ID\"].values\n",
    "gender = df[\"Gender(0:Female;1:Male)\"].values\n",
    "age = copy.deepcopy(df[\"Age\"].values)\n",
    "act_age = df[\"Age\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "e0e9b30cc44ece542c62d310e54d5a28cc35fef3",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "#for i in range(0,40):\n",
    "#    age[(age > (i * 2.5)) & (age <= ((i + 1) * 2.5))] = i\n",
    "#for i in range(0,20):\n",
    "#    age[(age > (i * 5.0)) & (age <= ((i + 1) * 5.0))] = i\n",
    "for i in range(0,10):\n",
    "    age[(age > (i * 10.0)) & (age <= ((i + 1) * 10.0))] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "2cc34d538dfa12ef9b5c9094aa5a9c0a00eb4df8",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([214., 150.,  94., 117., 127.,  32.,  19.,  10.]),\n",
       " array([0.   , 0.875, 1.75 , 2.625, 3.5  , 4.375, 5.25 , 6.125, 7.   ]),\n",
       " <a list of 8 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.hist(age,bins = 32)\n",
    "plt.hist(age,bins = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "31fdc4b603149a2a9570a93ba1394935d4c31bf6",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(age).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "08230eed5af6009e6c1cd8cff48fd3ab2e6b47a9",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender(0:Female;1:Male)</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2318</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2422</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2526</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2630</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Gender(0:Female;1:Male)  Age\n",
       "0   104                        1   33\n",
       "1  2318                        0   11\n",
       "2  2422                        1    9\n",
       "3  2526                        0   45\n",
       "4  2630                        0   37"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "cccc0b849c0c1223bdbdc8dff357888f40595b36",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, LSTM, Bidirectional, Dropout, Flatten, Dense, TimeDistributed, GlobalMaxPooling1D, Conv2D, Reshape, Activation, Add, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv1D, UpSampling1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.losses import categorical_crossentropy, binary_crossentropy, mae\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#Deep Convoluional LSTM model\n",
    "\"\"\"\n",
    "\n",
    "def get_model(n_timesteps,n_features):\n",
    "  inputs = Input(shape=(n_timesteps,n_features,))\n",
    "  x = Conv1D(256, 8, padding='same', activation='relu')(inputs)\n",
    "  x = Conv1D(256, 8, padding='same', activation='relu')(x)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(128, 8, padding='same', activation='relu')(x)\n",
    "  x = resblock(x,128,8)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(64, 8, padding='same', activation='relu')(x)\n",
    "  x = resblock(x,64,8)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(16, 8, padding='same', activation='relu')(x)\n",
    "  x = resblock(x,16,8)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(8, 4, padding='same', activation='relu')(x)\n",
    "  x = resblock(x,8,4)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Bidirectional(LSTM(10,return_sequences=True))(x)\n",
    "  x = Bidirectional(LSTM(10))(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  predictions = Dense(1, activation='sigmoid')(x)\n",
    "  \n",
    "  model = Model(inputs=inputs, outputs = predictions)\n",
    "  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "  return model \n",
    "\n",
    "def resblock(x, filters, kernel_size):\n",
    "    x_ = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x_ = BatchNormalization()(x_)\n",
    "    x_ = Activation(LeakyReLU())(x_)\n",
    "    x_ = Conv1D(filters, kernel_size, padding='same')(x_)\n",
    "    x = Add()([x_, x])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(LeakyReLU())(x)\n",
    "    return x\n",
    "\n",
    "\"\"\"\n",
    "def get_model(n_timesteps,n_features):\n",
    "  inputs = Input(shape=(n_timesteps,n_features,))\n",
    "  x = Conv1D(256, 11, padding='same', activation='relu')(inputs)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(256, 11, padding='same', activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "  x = Conv1D(128, 11, padding='same', activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Conv1D(64, 11, padding='same', activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Bidirectional(LSTM(100,return_sequences=True))(x)\n",
    "  x = Bidirectional(LSTM(100))(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  \n",
    "  x_gender = Dense(100, activation='relu')(x)\n",
    "  gender = Dense(1, activation='sigmoid',name='gender')(x_gender)\n",
    "  \n",
    "  x_age = Dense(100, activation='relu')(x)\n",
    "  age = Dense(8, activation='softmax',name='age')(x_age)\n",
    "  \n",
    "  #x_data = Dense(100, activation='relu')(x)\n",
    "  #data = Dense(3, activation='softmax',name='dataset')(x_data)\n",
    "  \n",
    "    \n",
    "  outputs = [gender, age]\n",
    "  \n",
    "  model = Model(inputs=inputs, outputs = outputs)\n",
    "  sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "  model.compile(loss={'gender': binary_crossentropy, 'age': categorical_crossentropy},\n",
    "                  loss_weights={'gender': 0.50, 'age': 0.50},\n",
    "                optimizer= \"adam\", metrics=['accuracy'])\n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "e049bd444d6a72adfb1c239b05a80ef5cceb7e60",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max(y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        temp = y_pred[i]\n",
    "        temp[np.argmax(temp)] = 1\n",
    "        temp[temp != 1] = 0\n",
    "        y_pred[i] = temp\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "5e63f15167f11bfbdf4076cec53c14e42a59a43a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oversample(x_train, gender_train, age_train, dataset_train, limit):\n",
    "    age_train_index = np.argmax(age_train,axis = 1)\n",
    "    ls_class_size = []\n",
    "    for i in range(0,8):\n",
    "        ls_class_size.append(np.sum(age_train_index == i))\n",
    "\n",
    "    max_class_size = max(ls_class_size)\n",
    "    max_index = np.argmax(ls_class_size)\n",
    "    aug_x = []\n",
    "    aug_age = []\n",
    "    aug_gender = []\n",
    "    aug_dataset = []\n",
    "\n",
    "    for i in tqdm(range(0,8)):\n",
    "        if(i == max_index):\n",
    "            continue\n",
    "        c = 0\n",
    "        if(ls_class_size[i] == 0):\n",
    "            continue\n",
    "        temp = []\n",
    "        temp_age = []\n",
    "        temp_gender = []\n",
    "        temp_dataset= []\n",
    "        while((ls_class_size[i] + c) <= max_class_size):\n",
    "            index = random.randrange(ls_class_size[i])\n",
    "            temp.append(x_train[age_train_index == i][index])\n",
    "            temp_age.append(age_train[age_train_index == i][index])\n",
    "            temp_gender.append(gender_train[age_train_index == i][index])\n",
    "            temp_dataset.append(dataset_train[age_train_index == i][index])\n",
    "            c += 1\n",
    "            if(c == limit):\n",
    "                break\n",
    "        aug_x.extend(np.array(temp))\n",
    "        aug_age.extend(np.array(temp_age))\n",
    "        aug_gender.extend(np.array(temp_gender))\n",
    "        aug_dataset.extend(np.array(temp_dataset))\n",
    "        del temp\n",
    "        del temp_age\n",
    "        del temp_gender\n",
    "        del temp_dataset\n",
    "        gc.collect()\n",
    "    aug_x = np.array(aug_x)\n",
    "    aug_age = np.array(aug_age)\n",
    "    aug_gender = np.array(aug_gender)\n",
    "    aug_dataset = np.array(aug_dataset)\n",
    "    \n",
    "    return aug_x, aug_age, aug_gender, aug_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "3caa212bb9a66a6e95587697504f5d59a9398b28",
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/549 [00:00<00:58,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 610 TEST: 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [00:49<00:00, 11.03it/s]\n",
      "100%|██████████| 61/61 [00:01<00:00, 49.03it/s]\n",
      "100%|██████████| 153/153 [00:03<00:00, 50.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 12071\n",
      "Valid size: 783\n",
      "Test size: 1897\n",
      "Train on 12071 samples, validate on 783 samples\n",
      "Epoch 1/5\n",
      "12071/12071 [==============================] - 68s 6ms/step - loss: 1.2004 - gender_loss: 0.6022 - age_loss: 1.7986 - gender_acc: 0.6613 - age_acc: 0.2859 - val_loss: 1.2883 - val_gender_loss: 0.6289 - val_age_loss: 1.9476 - val_gender_acc: 0.6590 - val_age_acc: 0.2465\n",
      "Epoch 2/5\n",
      "12071/12071 [==============================] - 62s 5ms/step - loss: 0.9887 - gender_loss: 0.4456 - age_loss: 1.5318 - gender_acc: 0.7908 - age_acc: 0.4051 - val_loss: 1.4159 - val_gender_loss: 0.7303 - val_age_loss: 2.1015 - val_gender_acc: 0.6079 - val_age_acc: 0.2069\n",
      "Epoch 3/5\n",
      "12071/12071 [==============================] - 62s 5ms/step - loss: 0.8781 - gender_loss: 0.3747 - age_loss: 1.3815 - gender_acc: 0.8340 - age_acc: 0.4625 - val_loss: 1.0864 - val_gender_loss: 0.3990 - val_age_loss: 1.7738 - val_gender_acc: 0.8020 - val_age_acc: 0.3231\n",
      "Epoch 4/5\n",
      "12071/12071 [==============================] - 62s 5ms/step - loss: 0.7981 - gender_loss: 0.3153 - age_loss: 1.2809 - gender_acc: 0.8657 - age_acc: 0.4965 - val_loss: 1.0434 - val_gender_loss: 0.4003 - val_age_loss: 1.6864 - val_gender_acc: 0.8186 - val_age_acc: 0.3780\n",
      "Epoch 5/5\n",
      "12071/12071 [==============================] - 63s 5ms/step - loss: 0.7302 - gender_loss: 0.2836 - age_loss: 1.1769 - gender_acc: 0.8836 - age_acc: 0.5324 - val_loss: 1.3281 - val_gender_loss: 0.6543 - val_age_loss: 2.0019 - val_gender_acc: 0.7229 - val_age_acc: 0.2899\n",
      "0.7231833910034602\n",
      "0.2179930795847751\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,) (289,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6a40d65a7536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;31m#mean_age = age_pred_index * 5.0 + 2.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mmean_age\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mage_pred_index\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_age_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_age\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0mls_mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_age_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_age\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (289,) "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "\n",
    "ls_acc = []\n",
    "ls_mae = []\n",
    "length = 500\n",
    "\n",
    "datasets = label.columns[4:]\n",
    "file_name=['AutomaticExtractionData_IMUZCenter','ManualExtractionData/IMUZCenter','ManualExtractionData/IMUZRight',\n",
    "          'ManualExtractionData/IMUZLeft','ManualExtractionData/Android']\n",
    "action_name=['_Walk_1','_Walk_2','_SlopeDown','_SlopeUp']\n",
    "sensor_loc = [\"CenterSensor\", \"RightSensor\", \"LeftSensor\"]\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "for train_index, test_index in skf.split(ids, gender):\n",
    "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "    ids_train, ids_test = ids[train_index], ids[test_index]\n",
    "    gender_train, gender_test = gender[train_index], gender[test_index]\n",
    "    age_dummy = to_categorical(age)\n",
    "    age_train, age_test = age_dummy[train_index], age_dummy[test_index]\n",
    "    #age_train, age_test = act_age[train_index], act_age[test_index]\n",
    "    _, act_age_test = act_age[train_index], act_age[test_index]\n",
    "    ids_train, ids_valid, gender_train, gender_valid, age_train, age_valid  = train_test_split(ids_train, gender_train, age_train,  test_size=0.10, random_state=42)\n",
    "    \n",
    "    x_train = []\n",
    "    new_y_train = []\n",
    "    new_gender_train = []\n",
    "    new_age_train = []\n",
    "    sensor_train = []\n",
    "    for i in tqdm(range(0,len(ids_train))):\n",
    "        subject_id = change_ID_number(str(ids_train[i]))\n",
    "        for k in range(0,len(file_name) - 1):\n",
    "            for l in range(0,len(action_name)):\n",
    "                try:\n",
    "                    #for c in range(0,3):\n",
    "                        df_subject = generate_read_table(path_name,file_name[k], action_name[l],subject_id,label)\n",
    "                        sc = StandardScaler()\n",
    "                        df_subject = pd.DataFrame(sc.fit_transform(df_subject))\n",
    "                        temp_x = yipeng_preprocessing(df_subject.values, length)\n",
    "                        x_train.append(temp_x)\n",
    "                        new_gender_train.append(gender_train[i])\n",
    "                        new_age_train.append(age_train[i])\n",
    "                        if(k == 0 or k == 1):\n",
    "                            sensor_train.append(0)\n",
    "                        elif(k == 2):\n",
    "                            sensor_train.append(1)\n",
    "                        elif(k == 3):\n",
    "                            sensor_train.append(2)\n",
    "                except: \n",
    "                    continue\n",
    "                \n",
    "        for k in range(0,3):\n",
    "            try:\n",
    "                df_subject = generate_read_table(path_name_act,'SimilarAction',sensor_loc[k],subject_id,label)\n",
    "                del df_subject[\"Label\"]\n",
    "                sc = StandardScaler()\n",
    "                df_subject = pd.DataFrame(sc.fit_transform(df_subject))\n",
    "                #temp_x = yipeng_preprocessing(df_subject.values, length)\n",
    "                start_index = 0\n",
    "                while(start_index + length < len(df_subject)):\n",
    "                    temp_x = df_subject.values[start_index:start_index + length]\n",
    "                    x_train.append(temp_x)\n",
    "                    new_gender_train.append(gender_train[i])\n",
    "                    new_age_train.append(age_train[i])\n",
    "                    sensor_train.append(k)\n",
    "                    start_index += length\n",
    "            except: \n",
    "                continue\n",
    "            \n",
    "    x_valid = []\n",
    "    new_gender_valid = []\n",
    "    new_age_valid = []\n",
    "    sensor_valid = []\n",
    "    \n",
    "    for i in tqdm(range(0,len(ids_valid))):\n",
    "        subject_id = change_ID_number(str(ids_valid[i]))\n",
    "        for k in range(0,3):\n",
    "            try:\n",
    "                df_subject = generate_read_table(path_name_act,'SimilarAction',sensor_loc[k],subject_id,label)\n",
    "                del df_subject[\"Label\"]\n",
    "                sc = StandardScaler()\n",
    "                df_subject = pd.DataFrame(sc.fit_transform(df_subject))\n",
    "                start_index = 0\n",
    "                while(start_index + length < len(df_subject)):\n",
    "                    temp_x = df_subject.values[start_index:start_index + length]\n",
    "                    x_valid.append(temp_x)\n",
    "                    new_gender_valid.append(gender_valid[i])\n",
    "                    new_age_valid.append(age_valid[i])\n",
    "                    sensor_valid.append(k)\n",
    "                    start_index += length \n",
    "            except:\n",
    "                continue\n",
    "           \n",
    "    x_test = []\n",
    "    new_gender_test = []\n",
    "    new_age_test= []\n",
    "    new_act_age_test = []\n",
    "    ls_count = []\n",
    "     \n",
    "    for i in tqdm(range(0,len(ids_test))):\n",
    "        subject_id = change_ID_number(str(ids_test[i]))\n",
    "        for k in range(0,3):\n",
    "            try:\n",
    "                df_subject = generate_read_table(path_name_act,'SimilarAction',sensor_loc[k],subject_id,label)\n",
    "                del df_subject[\"Label\"]\n",
    "                sc = StandardScaler()\n",
    "                df_subject = pd.DataFrame(sc.fit_transform(df_subject))\n",
    "                start_index = 0\n",
    "                c = 0\n",
    "                while(start_index + length < len(df_subject)):\n",
    "                    temp_x = df_subject.values[start_index:start_index + length]\n",
    "                    x_test.append(temp_x)                    \n",
    "                    start_index += length\n",
    "                    c += 1\n",
    "                ls_count.append(c)\n",
    "                new_gender_test.append(gender_test[i])\n",
    "                new_age_test.append(age_test[i])\n",
    "                new_act_age_test.append(act_age_test[i])\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    print(\"Train size: \" + str(len(x_train)))\n",
    "    print(\"Valid size: \" + str(len(x_valid)))\n",
    "    print(\"Test size: \" + str(len(x_test)))\n",
    "    x_train = np.array(x_train)\n",
    "    x_valid = np.array(x_valid)\n",
    "    x_test = np.array(x_test)\n",
    "    gender_train = np.array(new_gender_train)\n",
    "    gender_valid = np.array(new_gender_valid)\n",
    "    gender_test = np.array(new_gender_test)\n",
    "    age_train = np.array(new_age_train)\n",
    "    age_valid = np.array(new_age_valid)\n",
    "    age_test = np.array(new_age_test)\n",
    "    act_age_test = np.array(new_act_age_test)\n",
    "        \n",
    "    sensor_train = to_categorical(sensor_train)\n",
    "    #sensor_valid = to_categorical(sensor_valid)\n",
    "        \n",
    "    #del new_gender_train, new_gender_valid, new_gender_test, new_age_train, new_age_valid, new_age_test, new_act_age_test\n",
    "    #gc.collect()\n",
    "    \n",
    "    #aug_x, aug_age, aug_gender, aug_sensor = oversample(x_train, gender_train, age_train, sensor_train, 1000)\n",
    "    #x_train = np.concatenate([x_train,aug_x])\n",
    "    #age_train = np.concatenate([age_train,aug_age])\n",
    "    #gender_train = np.concatenate([gender_train,aug_gender])\n",
    "    #sensor_train = np.concatenate([sensor_train,aug_sensor])\n",
    "    \n",
    "    model = get_model(x_train.shape[1],x_train.shape[2])\n",
    "    #result = model.fit(x_train, [gender_train, age_train, sensor_train], validation_data = (x_valid,[gender_valid, age_valid, sensor_valid]),epochs= 15, batch_size = 256)\n",
    "    result = model.fit(x_train, [gender_train, age_train], validation_data = (x_valid,[gender_valid, age_valid]),epochs= 10, batch_size = 256)   \n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    #del x_train, gender_train, age_train, sensor_train, x_valid, gender_valid, age_valid, sensor_valid\n",
    "    gc.collect()\n",
    "    \n",
    "    gender_pred = []\n",
    "    age_pred = []\n",
    "    c = 0\n",
    "    for i in range(len(ls_count)):\n",
    "        gender_pred.append(y_pred[0][c:c + ls_count[i]].mean())\n",
    "        age_pred.append(np.mean(y_pred[1][0:0 + ls_count[i]], axis = 0))\n",
    "        c += ls_count[i]\n",
    "    gender_pred = np.array(gender_pred)\n",
    "    age_pred = np.array(age_pred)\n",
    "    \n",
    "    gender_pred[gender_pred < 0.5] = 0\n",
    "    gender_pred[gender_pred >= 0.5] = 1\n",
    "    print(accuracy_score(gender_pred,gender_test))\n",
    "    ls_acc.append(accuracy_score(gender_pred,gender_test))\n",
    "    \n",
    "    age_pred = get_max(age_pred)\n",
    "    print(accuracy_score(np.array(age_pred),age_test))\n",
    "    _, age_pred_index = np.where(age_pred == 1.0)\n",
    "    #mean_age = age_pred_index * 2.5 + 1.25\n",
    "    #mean_age = age_pred_index * 5.0 + 2.5\n",
    "    mean_age = age_pred_index * 10.0 + 5.0\n",
    "    print(np.mean(abs(act_age_test - mean_age)))\n",
    "    ls_mae.append(np.mean(abs(act_age_test - mean_age)))\n",
    "    \n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f2aeb95895bb42ee7f8212a6851089e93adff57",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbacc0b863dfd8c5ec30d837a971a42dcb2a1fe5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred[1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "a49471a406bcade2514cf1ab47bc48ae201ddbf1",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_age_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af1f6dd97a7e18d736cd99ae4ebab6613be093c7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a3a79f4fb773a46921e22a37e02fc1084c373d9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.mean(abs(act_age_test - age_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04a53df41d0e3ba9466889a2dcb64615a8920d29",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_pred = []\n",
    "c = 0\n",
    "for i in range(len(ls_count)):\n",
    "    age_pred.append(np.mean(y_pred[1][0:0 + ls_count[i]], axis = 0))\n",
    "    c += ls_count[i]\n",
    "age_pred = np.array(age_pred)\n",
    "#age_pred = get_max(age_pred)\n",
    "print(accuracy_score(age_pred,age_test))\n",
    "_, age_pred_index = np.where(age_pred == 1.0)\n",
    "#mean_age = age_pred_index * 10.0 + 5.0\n",
    "print(np.mean(abs(act_age_test - mean_age)))\n",
    "ls_mae.append(np.mean(abs(act_age_test - mean_age)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e53f80bc4449777afbe8ddb8f899f0c0a1339dc0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_pred = []\n",
    "c = 0\n",
    "for i in range(len(ls_count)):\n",
    "    temp = get_max(np.array(y_pred[1][0:0 + ls_count[i]]))\n",
    "    _, age_pred_index = np.where(temp == 1.0)\n",
    "    mean_age = age_pred_index * 10.0 + 5.0\n",
    "    age_pred.append(np.mean(mean_age))\n",
    "    c += ls_count[i]\n",
    "age_pred = np.array(age_pred)\n",
    "print(np.mean(abs(act_age_test - age_pred)))\n",
    "ls_mae.append(np.mean(abs(act_age_test - age_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "471f645e8fd68c79da8815590edc3d4b13015d33",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ls_count\n",
    "act_age_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f284bcbffbafcc17d1c92140e715653ddc4036ec",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age_pred = []\n",
    "c = 0\n",
    "for i in range(len(ls_count)):\n",
    "    temp = get_max(np.array(y_pred[1][0:0 + ls_count[i]]))\n",
    "    print(sum(temp))\n",
    "    mean_age = np.argmax(sum(temp)) * 10.0 + 5.0\n",
    "    age_pred.append(mean_age)\n",
    "    c += ls_count[i]\n",
    "age_pred = np.array(age_pred)\n",
    "print(np.mean(abs(act_age_test - age_pred)))\n",
    "ls_mae.append(np.mean(abs(act_age_test - age_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3750a40568b6c2907e02aea3425202f85f347532",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7f1ada278e1957b56175894b5404f8cf58e98c3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot(ls_acc)\n",
    "plt.savefig(\"result_gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86c1dcf08f00dbf357a9a13fa3f8a2299f24c9ed",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot(ls_mae)\n",
    "plt.savefig(\"result_age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd1c665d764a2e72d7dc13d602b5914750294f4e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model(x_train.shape[1],x_train.shape[2])\n",
    "result = model.fit(x_train, [gender_train, age_train, sensor_train], validation_data = (x_valid,[gender_valid, age_valid, sensor_valid]),epochs= 10, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4755d9825f767001b3c4db969e5097e824fbb616",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
